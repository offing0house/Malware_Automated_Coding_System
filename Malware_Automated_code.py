import os
import pickle

import pefile
from self import self
from sklearn.feature_extraction import FeatureHasher
import numpy
import random
# from sklearn.ensemble import GradientBoostingClassifier
from sklearn.ensemble import RandomForestClassifier
from sklearn import  metrics
from matplotlib  import pyplot
from sklearn.linear_model import LogisticRegression
from sklearn.metrics import  f1_score
from sklearn.model_selection import  KFold

def pecheck(filename):
    f = open(filename,"rb")
    bytes = f.read(2)
    return bytes == b'MZ'

def get_string_features(filename, min_length, hasher):
        string_features = {}
        strings = os.popen("strings '{0}'".format(filename)).read()
        strings = list(set(strings.split("\n")))


        i=0
        if len(header_features)>i:
            set_string = header_features[i]
            list_convert = list(set_string)
            strings.extend(list_convert)
        i+=1



        for str in strings:
             if len(str) >= min_length:
                  string_features[str] = 1





        hashed_features = hasher.transform([string_features])
        hashed_features = hashed_features.todense()
        hashed_features = numpy.asarray(hashed_features)
        hashed_features = hashed_features[0]
        return hashed_features



def get_header_(filename):
        iat_list = set()
        try:
            pe = pefile.PE(filename)
            pe.parse_data_directories()
            for entry in pe.DIRECTORY_ENTRY_IMPORT:
                if entry is not None:
                    for imp in entry.imports:
                        iat_list.add(hex(imp.address))

            IATRVA = str(hex(pe.OPTIONAL_HEADER.DATA_DIRECTORY[12].VirtualAddress))
            ExportSize = str(hex(pe.OPTIONAL_HEADER.DATA_DIRECTORY[0].Size))
            ResSize = str(hex(pe.OPTIONAL_HEADER.DATA_DIRECTORY[2].Size))
            TimeDateStamp = str(hex(pe.FILE_HEADER.TimeDateStamp))
            NumberOfSections = str(hex(pe.FILE_HEADER.NumberOfSections))
            Characteristics = str(hex(pe.FILE_HEADER.Characteristics))
            AddressOfEntryPoint = str(hex(pe.OPTIONAL_HEADER.AddressOfEntryPoint))
            SizeOfHeaders = str(hex(pe.OPTIONAL_HEADER.SizeOfHeaders))

            iat_list.add(IATRVA)
            iat_list.add(ExportSize)
            iat_list.add(ResSize)
            iat_list.add(TimeDateStamp)
            iat_list.add(NumberOfSections)
            iat_list.add(Characteristics)
            iat_list.add(AddressOfEntryPoint)
            iat_list.add(SizeOfHeaders)
            header_features.append(iat_list)
        except:
            pass






hasher = FeatureHasher(n_features=200)

benignware_paths = []
for root,dirs,paths in os.walk('/home/osboxes/malware_data_science/ch8/data/benignware'):
    for path in paths:
        full_path = os.path.join(root,path)
        if pecheck(full_path):
            benignware_paths.append(full_path)

malware_paths = []
for root,dirs,paths in os.walk('/home/osboxes/malware_data_science/ch8/data/malware'):
    for path in paths:
        full_path = os.path.join(root,path)
        if pecheck(full_path):
            malware_paths.append(full_path)

global header_features
header_features =list()
for i in range(0,len(malware_paths),1):
    get_header_(malware_paths[i])
for i in range(0,len(benignware_paths),1):
    get_header_(benignware_paths[i])


X = []
for filename in malware_paths + benignware_paths:
    X.append(get_string_features(filename, 3, hasher))

y = [1 for i in range(len(malware_paths))] + [0 for i in range(len(benignware_paths))]
X,y = numpy.array(X),numpy.array(y)
indicies = [i for i in range(len(y))]
random.shuffle(indicies)
X,y = X[indicies], y[indicies]
kfold = KFold(n_splits=10)

# LogistcRegression

# for indicies_train, indicies_test in kfold.split(indicies):
#     training_X, training_y = X[indicies_train], y[indicies_train]
#     test_X, test_y = X[list(indicies_test)], y[list(indicies_test)]
#
#     classifier = LogisticRegression(max_iter=500)
#     classifier.fit(training_X, training_y)
#
#     scores = classifier.predict_proba(test_X)[:, -1]
#
#     y_pred = [0 if score < 0.3 else 1 for score in scores]
#
#     f1 = f1_score(test_y, y_pred)
#     print(f1)

# RandomForest

for indicies_train, indicies_test in kfold.split(indicies):
    training_X, training_y = X[indicies_train], y[indicies_train]
    test_X, test_y = X[list(indicies_test)], y[list(indicies_test)]

    classifier = RandomForestClassifier()
    classifier.fit(training_X, training_y)

    scores = classifier.predict_proba(test_X)[:, -1]
    y_pred = [0 if score < 0.5 else 1 for score in scores]

    f1 = f1_score(test_y, y_pred)
    print(f1)



fpr,tpr,thresholds = metrics.roc_curve(test_y,scores)

pyplot.plot(fpr,tpr,'r-')
pyplot.xlabel("Detector false positive rate")
pyplot.ylabel("Detector true positive rate")
pyplot.title("Detector ROC Curve")
pyplot.savefig("roc_curves_Random.png")








